{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\impex\\Desktop\\w13\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Open the PDF file\n",
    "with pdfplumber.open(\"271_AI Lect Notes.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        # Extract text from each page\n",
    "        text = page.extract_text()\n",
    "        if text:  # Check if text is not None\n",
    "            rows = text.split('\\n')\n",
    "            for row in rows:\n",
    "                data.append([row])  # Store as a single-item list to create a DataFrame later\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"text\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\impex\\Desktop\\w13\\myenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = []\n",
    "for text in df[\"text\"]:\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True\n",
    "    )\n",
    "    tokenized_data.append(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for inputs in tokenized_data:\n",
    "    outputs = model(**inputs)  # Use ** to unpack the dictionary\n",
    "    embeddings.append(outputs.last_hidden_state[:, 0, :].detach().numpy())  # Detach and convert to numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"ef1ce0e6-971d-4119-abae-8068f14edfae\"  # Replace with your Pinecone API key\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"genai\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,  \n",
    "        metric='euclidean',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-west-2'\n",
    "        )\n",
    "    )\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded batch 1\n",
      "Successfully uploaded batch 2\n",
      "Successfully uploaded batch 3\n",
      "Successfully uploaded batch 4\n",
      "Successfully uploaded batch 5\n",
      "Successfully uploaded batch 6\n",
      "Successfully uploaded batch 7\n",
      "Successfully uploaded batch 8\n",
      "Successfully uploaded batch 9\n",
      "Successfully uploaded batch 10\n",
      "Successfully uploaded batch 11\n",
      "Successfully uploaded batch 12\n",
      "Successfully uploaded batch 13\n",
      "Successfully uploaded batch 14\n",
      "Successfully uploaded batch 15\n",
      "Successfully uploaded batch 16\n",
      "Successfully uploaded batch 17\n",
      "Successfully uploaded batch 18\n",
      "Successfully uploaded batch 19\n",
      "Successfully uploaded batch 20\n",
      "Successfully uploaded batch 21\n",
      "Successfully uploaded batch 22\n",
      "Successfully uploaded batch 23\n",
      "Successfully uploaded batch 24\n",
      "Successfully uploaded batch 25\n",
      "Successfully uploaded batch 26\n",
      "Successfully uploaded batch 27\n",
      "Successfully uploaded batch 28\n",
      "Successfully uploaded batch 29\n",
      "Successfully uploaded batch 30\n",
      "Successfully uploaded batch 31\n",
      "Successfully uploaded batch 32\n",
      "Successfully uploaded batch 33\n",
      "Successfully uploaded batch 34\n",
      "Successfully uploaded batch 35\n",
      "Successfully uploaded batch 36\n",
      "Successfully uploaded batch 37\n",
      "Successfully uploaded batch 38\n",
      "Successfully uploaded batch 39\n",
      "Successfully uploaded batch 40\n",
      "Successfully uploaded batch 41\n",
      "Successfully uploaded batch 42\n",
      "Successfully uploaded batch 43\n"
     ]
    }
   ],
   "source": [
    "# Set batch size and request timeout\n",
    "batch_size = 100  # Adjust batch size\n",
    "timeout = 60  # Adjust timeout value\n",
    "\n",
    "# Add embeddings to Pinecone index in batches\n",
    "for i in range(0, len(embeddings), batch_size):\n",
    "    batch = embeddings[i:i+batch_size]\n",
    "    ids = [str(idx) for idx in range(i, i + len(batch))]\n",
    "    try:\n",
    "        index.upsert([{\"id\": id, \"values\": emb.flatten().tolist()} for id, emb in zip(ids, batch)], _request_timeout=timeout)\n",
    "        print(f\"Successfully uploaded batch {i//batch_size + 1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading batch {i//batch_size + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"C:/Users/impex/Desktop/w13/model.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "tokenizer.save_pretrained(\"tokenizer\")\n",
    "print(\"Model and tokenizer saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
